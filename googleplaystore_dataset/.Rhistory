head(beaver1)
n_beaver1<-beaver1
n_beaver2<-beaver2
n_beaver1<-cbind(n_beaver1,rep.int(1,length(n_beaver1[1])))
head(beaver1)
head(n_beaver1)
n_beaver1<- beaver1
n_beaver1<-cbind(n_beaver1,id= rep.int(1,length(n_beaver1[1])))
head(bbeaver1)
head(n_beaver1)
n_beaver2<-cbind(n_beaver2,id= rep.int(2,length(n_beaver2[1])))
head(nn_beaver1)
head(n_beaver2)
length(n_beaver1)
seq_along(n_beaver1)
n_beaver1
c_beaver<-rbind(n_beaver1,n_beaver2)
c_beaver
subset(c_beaver,activ==1)
a<- c(1,2,3,4,5,7,2,3,6,7)
(b<-factor(a))
rm(list=ls())
formatC(pi,digits=16)
x <- c(  "Swan swam over the pond, Swim swan swim!",  "Swan swam back again - Well swum swan!" )
strsplit(x,'-?',fixed=TRUE)
strsplit(x,' '|'-', fixed=TRUE)
strsplit(x,' ',fixed = TRUE)
a<-strsplit(x,' ',fixed=TRUE)
a
strsplit(x,'-? ',fixed=TRUE)
x
class(x)
xơ1
x[1]
strplit(x,'-? ')
strsplit(x,'-? ')
strsplit(x,',? -? ?')
three_d6 <- function(n) {  random_numbers <- matrix(    sample(6, 3 * n, replace = TRUE),    nrow = 3  )  colSums(random_numbers) }
three_d6 <- function(n) {
random_numbers <- matrix(
sample(6, 3 * n, replace = TRUE),
nrow = 3  )
colSums(random_numbers)
}
attr_score<-three_d6(1000)
attr_score
seq.int(16,66,10)
score<-c(3,4.5,6,8,9,12,13,15,16,17,18)
b<-cut(attr_score,score)
table(b)
rep.int(c(TRUE,FALSE),6)
two_d6 <- function(n)
{  random_numbers <- matrix(
sample(6, 2 * n, replace = TRUE),    nrow = 2  )
colSums(random_numbers) }
two_d6(6)
?sample?
l
?sample
sdices<-two_d6(10)
if (sdices %in% c(2,3,11)){
game_status<-FALSE
point<-NA
}else if (sdices %in% c(7,11)){
game_status<-TRUE
point<-NA
}else{
game_status<-NA
point<-sdices
}
(matrix(
scores=sdices,
game_status=game_status,
point= point
)
)
(matrix(
scores=sdices,
game_statu=game_status,
points= point
)
)
sdices<-two_d6(10)
if (sdices %in% c(2,3,11)){
game_status<-FALSE
point<-NA
}else if (sdices %in% c(7,11)){
game_status<-TRUE
point<-NA
}else{
game_status<-NA
point<-sdices
}
(matrix(
scores=sdices,
game_statu=game_status,
points= point
)
)
(data.frame(
scores=sdices,
game_statu=game_status,
points= point
)
)
sea_shells <- c(  "She", "sells", "sea", "shells", "by", "the", "seashore",  "The", "shells", "she", "sells", "are", "surely", "seashells",  "So", "if", "she", "sells", "shells", "on", "the", "seashore",  "I'm", "sure", "she", "sells", "seashore", "shells" )
nchar(sea_shells)
l<-nchar(sea_shells)
l[1]
for (i in range(1,length(sea_shells))){
message(sea_shells[1],' has length: ',l[i],'\n')
}
for (i in range(1,length(sea_shells))){
message(sea_shells[i],' has length: ',l[i],'\n')
}
length(sea_shells)
for (i in range(1,length(sea_shells))){
print(i)
#message(sea_shells[i],' has length: ',l[i],'\n')
}
for (i in sea_shells){
message(i,' has length: ',nchar(i),'\n')
}
nchar_sea_shells <- nchar(sea_shells)
for(i in min(nchar_sea_shells):max(nchar_sea_shells))
{
print(i)
#message("These words have ", i, " letters:")
#print(toString(unique(sea_shells[nchar_sea_shells == i])))
}
baby_gender_report <- function(gender) {
ifelse(gender=='male',"It's a boy!","It's a girl!")
}
genders <- c("male", "female", "other")
baby_gender_report(genders)
rm(list=ls())
library(plyr)
wayans <- list(
"Dwayne Kim" = list(),
"Keenen Ivory" = list(
"Jolie Ivory Imani",     "Nala",
"Keenen Ivory Jr",     "Bella",     "Daphne Ivory"  ),
Damon = list(    "Damon Jr",    "Michael",    "Cara Mia",
"Kyla"  ),
Kim = list(),  Shawn = list(    "Laila",    "Illia",    "Marlon"  ),  Marlon = list(    "Shawn Howell",    "Arnai Zachary"  ),  Nadia = list(),  Elvira = list(    "Damien",    "Chaunté"  ),  Diedre = list(    "Craig",    "Gregg",    "Summer",    "Justin",    "Jamel"  ),  Vonnie = list() )
laply(wayans,length)
llply(wayans,length)
head(state.x77)
class(state.x77)
d<-as.data.frame(state.x77)
head(d)
ddply(d,mean)
index(d)
row.names.data.frame(d)
dim.data.frame(d)
View(d)
class(row.names.data.frame(d))
apply(d,2,mean)
apply(d,2,std)
apply(d,2,sd)
time_for_commute <- function() {
#Choose a mode of transport for the day
mode_of_transport <- sample(
c("car", "bus", "train", "bike"),    size = 1,
prob = c(0.1, 0.2, 0.3, 0.4)  )
#Find the time to travel, depending upon mode of transport
time <- switch(
mode_of_transport,    car   = rlnorm(1, log(30), 0.5),
bus   = rlnorm(1, log(40), 0.5),    train = rnorm(1, 30, 10)
,    bike  = rnorm(1, 60, 5)  )
names(time) <- mode_of_transport
time
}
commute_times <- replicate(1000, time_for_commute())
commute_data <- data.frame(  time = commute_times,  mode = names(commute_times) )
commute_data
?quantile
ddply(commute_data,.mode,quantile)
ddply(commute_data,.(mode),quantile)
ddply(commute_data,.(mode),colwise(quantile))
ddply(commute_data,.(mode),summarize,quan= quantile(time))
ddply(commute_data,.(mode),quan75= quantile)
ddply(commute_data,.(mode),quan75= quantile(time,0.75))
ddply(commute_data,.(mode),quan75= quantile(time,0.75))
cls
commute_data
ddply(commute_data,.(mode),summarize,time75= quantile(time,0.75))
with(commute_data,tapply(time,mode,quantile,prob=0.75))
rm(list=ls())
rm(list=ls())
#get data
data(english_monarchs, package = "learningr")
head(english_monarchs)
th <- c("th", "ð", "þ")
sapply(th,  function(th)  {    sum(str_count(english_monarchs$name, th))  } ) ## th  ð  þ ## 74 26  7
#string detect
library(stringr)
#find row with not missing values
data("deer_endocranial_volume", package = "learningr")
#shorcut to remove any row with at least one missing value
na.omit(deer_endocranial_volume)
#throw an error if there is any missing value in dataframe
na.fail(deer_endocranial_volume)
deer_endocranial_volume
#shorcut to remove any row with at least one missing value
na.omit(deer_endocranial_volume)
head(deer_endocranial_volume)
is.na(deer_endocranial_volume[,6])
unique(deer_endocranial_volume[1,])
unique(deer_endocranial_volume$SkullID)
#convert between wide and long form
deer_wide <- deer_endocranial_volume[, 1:5]#wide form
deer_wide
library('reshape2')
deer_long <- melt(deer_wide, id.vars = "SkullID")
head(deer_long)
deer_long
melt(deer_wide, measure.vars = c("VolCT", "VolBead", "VolLWH", "VolFinarelli"))
# dcast function converts back from long to wide and returns the result as a data frame
deer_wide_again <- dcast(deer_long, SkullID ~ variable)
deer_wide_again
data(haru,package = 'learningr')
data(hafu,package = 'learningr')
head(hafu)
new_hafu<-hafu
head(new_hafu)
library('stringr')
father_question<-str_detect(new_hafu$Father,fixed('?'))
father_question
mother_question<-str_detect(new_hafu$Mother,fixed('?'))
new_hafu$mother_question<-mother_question
new_hafu$father_quesion<-father_question
names(new_hafu)
View(new_hafu)
?str_replace
new_hafu
new_hafu$Mother<- str_replace_all(new_hafu$Mother,'?','')
new_hafu$Mother<- str_replace(new_hafu$Mother,'?','')
str_replace(new_hafu$Mother,'?','')
str_replace(new_hafu$Mother,'(?)','')
str_replace(new_hafu$Mother,'[?]','')
new_hafu$Mother<-str_replace(new_hafu$Mother,'[?]','')
new_hafu$Father<-str_replace(new_hafu$Father,'[?]','')
view(new_hafu)
View(new_hafu)
library('reshape2')
head(hafu)
hafu_long<-melt
hafu_wide<- hafu[,c(3,5,6)]
hafu_wide
hafu_long<-melt(hafu_wide,id.vars='Character')
names(hafu_wide)
hafu_long
hafu_long <- melt(hafu, measure.vars = c("Father", "Mother"))
hafu_long
head(hafu_long)
top10_most_common<-function(x){
unique_ele<- unique(x)
fre<-sapply(unique_ele,function(unique_ele){sum(str_count(x,unique_ele))})
return (fre)
}
top10_most_common(hafu$Father)
library('dplyr')
top10_most_common<-function(df,fea){
temp<- df%>%group_by(fea)%>%summarise(nb_ele= length(fea))%>%arrange(desc(nb_ele))
}
top10_most_common(hafu,hafu$Father)
top10_most_common(hafu,Father)
top10_most_common(hafu,'Father')
?str_count
top10_most_common<-function(x){
unique_ele<- unique(x)
fre<-sapply(unique_ele,function(unique_ele){sum(str_count(x,unique_ele))})
fre
}
top10_most_common(hafu$Father)
top10_most_common<-function(x){
unique_ele<- as.vector(unique(x))
fre<-sapply(unique_ele,function(unique_ele){sum(str_count(x,unique_ele))})
fre
}
top10_most_common(hafu$Father)
View(new_hafu)
na.omit(new_hafu)
top10_most_common(new_hafu$Father)
unique(new_hafu$Father)
str(unique(new_hafu$Father))
top10_v2 <- function(x) {  counts <- count(x)  head(arrange(counts, desc(freq)), 10) }
top10_v2 <- function(x) {  counts <- count(x)
head(arrange(counts, desc(freq)), 10) }
top10_v2(new_hafu$Father)
top10 <- function(x) {  counts <- table(x, useNA = "always")
head(sort(counts, decreasing = TRUE), 10) }
top10(hafu$Mother)
top10_v2(hafu$Mother)
count(hafu$Mother)
summarise(nb= count(hafu$Mother))
rm(list=ls())
#229
data(obama_vs_mccain,package = 'learningr')
dim(obama_vs_mccain)
head(obama_vs_mccain)
obama <- obama_vs_mccain$Obama
table(cut(obama, seq.int(0, 100, 10)))
?pmax
with(obama_vs_mccain, cor(Obama, McCain))
#scatter plot with ggplot2
ggplot(obama_vs_mccain, aes(Income, Turnout)) +  geom_point()
#scatter plot with ggplot2
library(ggplot2)
ggplot(obama_vs_mccain, aes(Income, Turnout)) +  geom_point()
ggplot(obama_vs_mccain, aes(Income, Turnout)) +  geom_point(color='violet',shape=20)
?scale_x_log10
ggplot(obama_vs_mccain, aes(Income, Turnout,fill='Region')) +  geom_point()
obama_vs_mccain$Region
ggplot(obama_vs_mccain) +  geom_point( aes(Income, Turnout,color='Region'),alpha=0.2)
ggplot(obama_vs_mccain) +  geom_point( aes(x=Income, y=Turnout,color='Region'),alpha=0.2)
ggplot(obama_vs_mccain) +  geom_point( aes(x=Income, y=Turnout,fill='Region'),alpha=0.2)
ggplot(obama_vs_mccain) +  geom_point( aes(x=Income, y=Turnout,color=Region),alpha=0.2)
data(crap_tag,package = 'learningr')
crap_tag
??crap_tag
with(obama_vs_mccain, hist(Obama))
with(obama_vs_mccain, hist(Obama,20))
#boxplot for base function
boxplot(Obama ~ Region, data = obama_vs_mccain)
?reorder
ovm <- within(  obama_vs_mccain,  Region <- reorder(Region, Obama, median) )
boxplot(Obama ~ Region, data = ovm)
ovm
#bar charts
ovm <- ovm[!(ovm$State %in% c("Alaska", "Hawaii")), ]
religions_long <- melt(  ovm,  id.vars = "State",  measure.vars = c("Catholic", "Protestant", "Non.religious", "Other") )
library('plyr')
religions_long <- melt(  ovm,  id.vars = "State",  measure.vars = c("Catholic", "Protestant", "Non.religious", "Other") )
??melt
library(reshape2)
religions_long <- melt(  ovm,  id.vars = "State",  measure.vars = c("Catholic", "Protestant", "Non.religious", "Other") )
ggplot(religions_long, aes(State, value, fill = variable)) +  geom_bar(stat = "identity") +  coord_flip()
#side by side bar chart
ggplot(religions_long, aes(State, value, fill = variable)) +  geom_bar(stat = "identity", position = "dodge") +  coord_flip()
cor(obama_vs_mccain$Unemployment,obama_vs_mccain$Obama)
ggplot(obama_vs_mccain,aes(Unemployment,Obama))+geom_point(color='red')
??aple_d_huez
??alpe_d_huez
data(alpe_d_huez,package = 'learningr')
head(alpe_d_huez)
data(alpe_d_huez2,package='learningr')
head(alpe_d_huez2)
ftime_withdrug<-alpe_d_huez2[alpe_d_huez2$DrugUse==TRUE,'NumericTime']
ftime_withdrug
View(alpe_d_huez2)
ftime_withoutdrug<-alpe_d_huez2[alpe_d_huez2$DrugUse==FALSE,'NumericTime']
ftime<-data.frame(withdrug= ftime_withdrug,withoutdrug= ftime_withoutdrug)
ggplot(ftime_withdrug)+geom_histogram(binwidth = 5)
length(ftime_withdrug)
length(ftime_withoutdrug)
hist(ftime_withdrug)
hist(ftime_withdrug,20)
hist(ftime_withoutdrug)
hist(ftime_withdrug)
ggplot(alpe_d_huez2, aes(NumericTime)) +  geom_histogram(binwidth = 2) +  facet_wrap(~ DrugUse)
?? gonorrhoea
data( gonorrhoea,package = 'learningr')
head( gonorrhoea)
View( gonorrhoea)
ggplot( gonorrhoea,aes(Age.Group,Rate))+geom_line()
ggplot( gonorrhoea,aes(Age.Group,Rate))+geom_line()+theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot( gonorrhoea,aes(Age.Group,-Rate))+geom_line()+theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot( gonorrhoea,aes(Age.Group,Rate))+geom_line()+theme(axis.text.x = element_text(angle = 30, hjust = 1))
ggplot(gonorrhoea, aes(Age.Group, Rate)) +  geom_bar(stat = "identity") +  facet_wrap(~ Year + Ethnicity + Gender)
ggplot(gonorrhoea, aes(Age.Group, Rate, group = Year, fill = Year)) +  geom_bar(stat = "identity", position = "dodge") +  facet_wrap(~ Ethnicity + Gender)
ggplot(gonorrhoea, aes(Age.Group, Rate, group = Year, color = Year)) +  geom_line() +  facet_grid(Ethnicity ~ Gender, scales = "free_y")
gonorrhoea
head(gonorrhoea)
unique(gonorrhoea$Ethnicity)
rm(list=ls())
#linear model
data(gonorrhoea,package = 'learningr')
model1 <- lm(Rate ~ Year + Age.Group + Ethnicity + Gender, gonorrhoea)
model1
head(gônrhoea)
head(gonorrhoea)
?quote
head(gglstore)
getwd()
setwd('D://analysis//data//googleplaystore_dataset')
gglstore<- read.csv('new_googleplaystore.csv')
head(gglstore)
unique(gglstore$Category)
library('dplyr')
library('ggplot2')
names(gglstore)
ggplot(gglstore,aes(Rating,Installs))+geom_point(color='blue',shape=30)
class(gglstore$Installs)
warnings()
ggplot(gglstore,aes(Rating,Installs))+geom_point()
any(is.na(gglstore$Rating))
any(is.na(gglstore$Installs))
is.na(gglstore$Installs)
gglstore<- na.omit(gglstore)
names(gglstore)
class(gglstore$Price)
gglstore$Size_mb[gglstore$Size_mb<0]<-0
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(sum_download_unit1000= sum(Installs)/1000,avg_rating= mean(Rating), sum_reviews= sum(Reviews),avg_size= mean(Size_mb)) %>% arrange(desc(sum_download_unit1000))
class(gglstore$Installs)
class(gglstore$Reviews)
rv<- as.numeric(gglstore$Reviews)
is.na(rv)
any(is.na(rv))
rm(rv)
gglstore$Reviews<- as.numeric(gglstore$Reviews)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(sum_download_unit1000= sum(Installs)/1000,avg_rating= mean(Rating), sum_reviews= sum(Reviews),avg_size= mean(Size_mb)) %>% arrange(desc(sum_download_unit1000))
summarise_by_category
View(summarise_by_category)
write.csv(summarise_by_category,file='summarise_by_category.csv')
unique(gglstore$Content.Rating)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),sum_download_unit1000= round(sum(Installs)/1000),avg_rating= mean(Rating), sum_reviews= sum(Reviews),avg_size= mean(Size_mb)) %>% arrange(desc(sum_download_unit1000))
View(summarise_by_category)
write.csv(summarise_by_category,file='summarise_by_category.csv')
unique(gglstore$Type)
summarise_by_category<- gglstore%>% group_by(Category)%>%
summarise(nb_app= length(Category),
percent_free_app= round((length(Type=='Free')/nb_app)*100,2),
sum_download_unit1000= round(sum(Installs)/1000),
percent_free_download= round(((sum(Install[Type=='Free'])/1000)/sum_download_unit1000)*100)
avg_rating= mean(Rating),
sum_reviews= sum(Reviews),
avg_size= mean(Size_mb))%>%
arrange(desc(sum_download_unit1000))
summarise_by_category<- gglstore%>% group_by(Category)%>%
summarise(nb_app= length(Category),
percent_free_app= round((length(Type=='Free')/nb_app)*100,2),
sum_download_unit1000= round(sum(Installs)/1000),
percent_free_download= ((sum(Install[Type=='Free'])/1000)/sum_download_unit1000)*100
avg_rating= mean(Rating),
sum_reviews= sum(Reviews),
avg_size= mean(Size_mb))%>%
arrange(desc(sum_download_unit1000))
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Type=='Free')/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Install[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Type=='Free')/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
source('D:/analysis/googleplaystore_analysis.R', echo=TRUE)
summarise_by_category
View(summarise_by_category)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Category[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Installs[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((Type=='Free')/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= length(Type=='Free')/nb_app*100,sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
class(gglstore)
class(gglstore$Reviews)
View(gglstore)
gglstore$Size_mb[gglstore$Size_mb<0]<-0
gglstore$Reviews<- as.numeric(gglstore$Reviews)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Category[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
View(summarise_by_category)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Category[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000),percent_free_download= ((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,avg_download_per_app= sum_download_unit1000/nb_app,avg_rating= mean(Rating),sum_reviews= sum(Reviews),avg_size= mean(Size_mb))%>% arrange(desc(sum_download_unit1000))
View(summarise_by_category)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Category[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000,2),percent_free_download= round(((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,2),avg_download_per_app= round(sum_download_unit1000/nb_app),avg_rating= round(mean(Rating),2),sum_reviews= sum(Reviews),avg_size= round(mean(Size_mb)),2)%>% arrange(desc(sum_download_unit1000))
View(summarise_by_category)
summarise_by_category<- na.omit(summarise_by_category)
dim(summarise_by_category)
unique(gglstore$Category)
View(summarise_by_category)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Category[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000,2),percent_free_download= round(((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,2),avg_download_per_app= round(sum_download_unit1000/nb_app),avg_rating= round(mean(Rating),2),sum_reviews= sum(Reviews),avg_size= round(mean(Size_mb),2)%>% arrange(desc(sum_download_unit1000))
View(summarise_by_category)
summarise_by_category<- gglstore%>% group_by(Category)%>% summarise(nb_app= length(Category),percent_free_app= round((length(Category[Type=='Free'])/nb_app)*100,2),sum_download_unit1000= round(sum(Installs)/1000,2),percent_free_download= round(((sum(Installs[Type=='Free'])/1000)/sum_download_unit1000)*100,2),avg_download_per_app= round(sum_download_unit1000/nb_app),avg_rating= round(mean(Rating),2),sum_reviews= sum(Reviews),avg_size= round(mean(Size_mb),2))%>% arrange(desc(sum_download_unit1000))
View(summarise_by_category)
summarise_by_category<- na.omit(summarise_by_category)
View(summarise_by_category)
write.csv(summarise_by_category,file='summarise_by_category.csv')
names(gglstore)
summarise_by_content<- gglstore%>%group_by(Content.Rating)%>%
summarise(
nb_app= length(Content.Rating),
total_download_unit1000= round(sum(Installs)/1000),
percent_download_free_app= round(sum(Installs[Type=='Free'])/1000/total_download_unit1000*100,2),
avg_rating= round(mean(Rating),2),
avg_size= round(mean(Size_mb),2)
) %>%arrange(desc(total_download_unit1000))
View(summarise_by_content)
summarise_by_content<- na.omit(summarise_by_content)#remove na values
View(summarise_by_content)
write.csv(summarise_by_content,file='summarise_by_content.csv')
class(gglstore$Last.Updated)
str(gglstore$Last.Updated)
gglstore$Last.Updated
now_ct<- Sys.time()
now_date<- as.Date(now_ct)
now_date
gglstore$Last.Updated<- as.character(gglstore$Last.Updated)
date<- strptime(gglstore$Last.Updated,'%d-%B-%y')
class(date)
head(date)
gglstore$Last.Updated
date<- strptime(gglstore$Last.Updated,'%B %d, %Y')
date
head(date,1)
head(gglstore$Last.Updated,1)
date[[1]]$date
date<- as.Date(data)
date<- as.Date(date)
date$day
head(date)
diff_week_last_update_from_now<- difftime(now_date, date,units='weeks')
diff_week_last_update_from_now
diff_week_last_update_from_now<- round(diff_week_last_update_from_now)
head(diff_week_last_update_from_now)
gglstore$diff_week_last_update_from_now<- diff_week_last_update_from_now
is.na(diff_week_last_update_from_now)
any(is.na(diff_week_last_update_from_now))
View(gglstore)
write.csv(gglstore,file='new_googleplaystore.csv')
